df2 = text2[duplicated(text2$datecomp),] %>%
select(datecomp,text)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
# Combine
df3 = full_join(df1,df2,by="datecomp")
df3 = na.omit(df3)
# Are there still duplicate dates?
length(which(duplicated(df3$datecomp)==TRUE))
# Repeat steps above: Split df3 data frame into df3a (non-duplicated rows) and df3b (duplicated rows)
df3a = df3[!duplicated(df3$datecomp),]
df3b = df3[duplicated(text2$datecomp),]
# Combine
df4 = full_join(df3a,df3b,by="datecomp")
df4 = na.omit(df4)
# Repeat
df5a = df4[!duplicated(df4$datecomp),]
df5b = df4[duplicated(df4$datecomp),]
# Combine
df5 = full_join(df5a,df5b,by="datecomp")
df5 = na.omit(df5)
length(which(duplicated(df5$datecomp)==TRUE))
# Repeat
df6a = df5[!duplicated(df5$datecomp),]
df6b = df5[duplicated(df5$datecomp),]
# Combine
df6 = full_join(df5,df6,by="datecomp")
# Combine
df6 = full_join(df6a,df6b,by="datecomp")
df6 = na.omit(df6)
length(which(duplicated(df6$datecomp)==TRUE))
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(stopwords)
library(lubridate)
library(RCurl)
library(dplyr)
rm(list = ls())
load("text.Rdata")
load("stocks.Rdata")
# Get the names of the companies we have stock price data for
companies = unique(stocks$Company)
# Add company names more used/or changed during time period
companies = c(companies,c("Statoil", "Marine Harvest", "Det Norske Oljeselskap",
"Apptix", "Clavis Pharma", "AqualisBraemar",
"Bergen Group", "Vik Sparebank", "Aurland Sparebank",
"Indre Sogn Sparebank", "Noreco", "Team Bane",
"Namsos Traffikkselskap", "PGS", "Solstad",
"PSI", "Ocean Technology"))
# 1. Which companies are never mentioned?
# Create data frame with "companies" column and "mentioned" column
comp.df = data.frame(companies,"mentioned" = 0)
# Create string with text from all articles (easier to search in than in each row)
articles = toString(text$text)   # Takes a minute or two
# Loop: for i in each row of comp.df, assign 1 to the "mentioned" column if a
# company name is found in the "articles" string and 0 if not
for(i in 1:nrow(comp.df)){
comp.df$mentioned[i] =
ifelse(str_detect(string = articles,
pattern = comp.df$companies[i])==TRUE,
1,NA)    # If company i is not detected in the "articles" string ,
}
# Remove companies that are never mentioned from the "companies" list
comp.df.new = na.omit(comp.df)
# Create new list with company names that are mentioned
companies = comp.df.new$companies
# New column in text data frame for company names
text$Company <- ""
# Loop to paste company names into new Company column
for (company in 1:length(companies)) {
for (t in 1:length(text$text)) {
if (grepl(companies[company], text[t,1], fixed = TRUE)) {
m <- gregexpr(companies[company], text[t,1])
ct <- text[t,4]
name <- toString(regmatches(text[t,1], m)[[1]])
name <- gsub(" ", "-", name)
text[t,4] <- paste(ct, name, sep = ", ")
}
text <- text[!text$Company=="",] # Remove rows with no company names
# Loop to remove company names that only get mentioned once per article
for (t in 1:length(text$Company)) {
for (c in companies) {
if (str_count(text[t,4], c) <= 1) {
text[t,4] <- gsub(c, "", text[t,4])
}
# Remove rows where only companies were mentioned once and commas
text$Company <- str_replace_all(text$Company, ",", " ")
text$Company <- gsub("^[[:space:]]+$", NA, text$Company)
text <- text[!(is.na(text$Company)),]
# Loop to choose the most mentioned company for each article
for (t in 1:length(text$Company)) {
for (c in companies) {
words <- strsplit(text[t,4], "[[:space:]]+")[[1]]
most <- tail(sort(words), 1)
text[t,4] <- text[t,4] %>% gsub(text[t,4], "", text[t,4]) %>%
gsub("", most, text[t,4])
}
# Replace - with spaces
text$Company <- gsub("-", " ", text$Company)
# Change old company names to new company names
text$Company <- text$Company %>%
gsub("Statoil", "Equinor", .) %>%
gsub("Marine Harvest", "Mowi", .) %>%
gsub("Det Norske Oljeselskap", "Aker BP", .) %>%
gsub("Apptix", "Carasent", .) %>%
gsub("Clavis Pharma|AqualisBraemar", "Aqualis", .) %>%
gsub("Bergen Group", "EndÃºr", .) %>%
gsub("'Vik Sparebank'|'Aurland Sparebank'|'Indre Sogn Sparebank'",
"Sogn Sparebank", .) %>%
gsub("Noreco", "Norwegian Energy Company", .) %>%
gsub("Team Bane", "NRC Group", .) %>%
gsub("Namsos Trafikkselskap", "NTS", .) %>%
gsub("PGS", "Petroleum Geo-Services", .) %>%
gsub("Solstad", "Solstad Farstad", .) %>%
gsub("PSI", "StrongPoint", .) %>%
gsub("Ocean Technology", "Subsea", .)
# Create row with date and company to identify instances where there are more than 1
# article about a company on a specific date:
text$datecomp = paste(text$date, text$Company)
# Select relevant columns
text2 = text %>%
select(datecomp,text,date,Company) %>%
group_by(datecomp)
# Split text data frame into df1 (non-duplicated rows) and d1b (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),]
df1b = text2[duplicated(text2$datecomp),]
# Check that all rows have been assigned to either d1 or d1b
nrow(df1)+nrow(df1b)-nrow(text)
# Split duplicated rows (d1fb) into df2 (non-duplicated rows) and df2b (duplicated rows)
# This is done to take into account 2 articles per company per day
df2 = df1b[!duplicated(df1b$datecomp),]
df2b = df1b[duplicated(df1b$datecomp),]
# Combine df1 (non-duplicated rows of 1 article per day) with df2 (non-duplicated
# rows of 2 articles per day)
df12 = full_join(df1,df2,by="datecomp")
# Split duplicated rows (df2b) into df3 (non-duplicated rows) and df3b (duplicated rows)
# This is done to take into account 3 articles per company per day
df3 = df2b[!duplicated(df2b$datecomp),]
df3b = df2b[duplicated(df2b$datecomp),]
# Combine df12 (non-duplicated rows of 1 or 2 articles per day) with df3 (non-duplicated
# rows of 3 articles per day)
df23 = full_join(df12,df3,by="datecomp")
# Split duplicated rows (df3b) into df4 (non-duplicated rows) and df4b (duplicated rows)
# This is done to take into account 4 articles per company per day
df4 = df3b[!duplicated(df3b$datecomp),]
df4b = df3b[duplicated(df3b$datecomp),]
# Combine df23 (non-duplicated rows of 1, 2 or 3 articles per day) with df4 (non-duplicated
# rows of 4 articles per day)
df34 = full_join(df23,df4,by="datecomp")
# Split duplicated rows (df4b) into df5 (non-duplicated rows) and df5b (duplicated rows)
# This is done to take into account 5 articles per company per day
df5 = df4b[!duplicated(df4b$datecomp),]
df5b = df4b[duplicated(df4b$datecomp),]
# Combine df34 (non-duplicated rows of 1, 2, 3 or 4 articles per day) with df5 (non-duplicated
# rows of 5 articles per day)
df45 = full_join(df34,df5,by="datecomp")
# Split duplicated rows (df5b) into df6 (non-duplicated rows) and df6b (duplicated rows)
# This is done to take into account 6 articles per company per day
df6 = df5b[!duplicated(df5b$datecomp),]
df6b = df5b[duplicated(df5b$datecomp),]
# Combine df45 (non-duplicated rows of 1, 2, 3, 4 or 5 articles per day) with df6 (non-duplicated
# rows of 6 articles per day)
df56 = full_join(df45,df6,by="datecomp")
# Split duplicated rows (df6b) into df7 (non-duplicated rows) and df7b (duplicated rows)
# This is done to take into account 7 articles per company per day
df7 = df6b[!duplicated(df6b$datecomp),]
df7b = df6b[duplicated(df6b$datecomp),]
# Combine df56 (non-duplicated rows of 1, 2, 3, 4, 5 or 6 articles per day) with df7 (non-duplicated
# rows of 7 articles per day)
df67 = full_join(df56,df7,by="datecomp")
# Split duplicated rows (df7b) into df8 (non-duplicated rows) and df8b (duplicated rows)
# This is done to take into account 8 articles per company per day
df8 = df7b[!duplicated(df7b$datecomp),]
df8b = df7b[duplicated(df7b$datecomp),]
# Combine df67 (non-duplicated rows of 1, 2, 3, 4, 5, 6 or 7 articles per day) with df8 (non-duplicated
# rows of 8 articles per day)
df78 = full_join(df67,df8,by="datecomp")
# Split duplicated rows (df8b) into df9 (non-duplicated rows) and df9b (duplicated rows)
# This is done to take into account 9 articles per company per day
df9 = df8b[!duplicated(df8b$datecomp),]
df9b = df8b[duplicated(df8b$datecomp),]
# Combine df78 (non-duplicated rows of 1, 2, 3, 4, 5, 6, 7 or 8 articles per day) with df9 (non-duplicated
# rows of 9 articles per day)
df89 = full_join(df78,df9,by="datecomp")
# Are there still duplicate dates?
length(which(duplicated(df9b$datecomp)==TRUE))    # We have reached the end
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Replace NAs with " " (tried a few methods, nothing works)
#df.end = str_replace(string = df.end,
#                     pattern = "NA",
#                     replacement = " ")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x)
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
# Remove all my unnecessary dfs hahaha :)
rm(list = ls(pattern = "^df"))
# Libraries
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(stopwords)
library(lubridate)
library(RCurl)
library(dplyr)
# Create row with date and company to identify instances where there are more than 1
# article about a company on a specific date:
text$datecomp = paste(text$date, text$Company)
# Select relevant columns
text2 = text %>%
select(datecomp,text,date,Company) %>%
group_by(datecomp)
# Split text data frame into df1 (non-duplicated rows) and d1b (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),]
df1b = text2[duplicated(text2$datecomp),]
# Check that all rows have been assigned to either d1 or d1b
nrow(df1)+nrow(df1b)-nrow(text)
# Split duplicated rows (d1fb) into df2 (non-duplicated rows) and df2b (duplicated rows)
# This is done to take into account 2 articles per company per day
df2 = df1b[!duplicated(df1b$datecomp),]
df2b = df1b[duplicated(df1b$datecomp),]
# Combine df1 (non-duplicated rows of 1 article per day) with df2 (non-duplicated
# rows of 2 articles per day)
df12 = full_join(df1,df2,by="datecomp")
# Split duplicated rows (df2b) into df3 (non-duplicated rows) and df3b (duplicated rows)
# This is done to take into account 3 articles per company per day
df3 = df2b[!duplicated(df2b$datecomp),]
df3b = df2b[duplicated(df2b$datecomp),]
# Combine df12 (non-duplicated rows of 1 or 2 articles per day) with df3 (non-duplicated
# rows of 3 articles per day)
df23 = full_join(df12,df3,by="datecomp")
# Split duplicated rows (df3b) into df4 (non-duplicated rows) and df4b (duplicated rows)
# This is done to take into account 4 articles per company per day
df4 = df3b[!duplicated(df3b$datecomp),]
df4b = df3b[duplicated(df3b$datecomp),]
# Combine df23 (non-duplicated rows of 1, 2 or 3 articles per day) with df4 (non-duplicated
# rows of 4 articles per day)
df34 = full_join(df23,df4,by="datecomp")
# Split duplicated rows (df4b) into df5 (non-duplicated rows) and df5b (duplicated rows)
# This is done to take into account 5 articles per company per day
df5 = df4b[!duplicated(df4b$datecomp),]
df5b = df4b[duplicated(df4b$datecomp),]
# Combine df34 (non-duplicated rows of 1, 2, 3 or 4 articles per day) with df5 (non-duplicated
# rows of 5 articles per day)
df45 = full_join(df34,df5,by="datecomp")
# Split duplicated rows (df5b) into df6 (non-duplicated rows) and df6b (duplicated rows)
# This is done to take into account 6 articles per company per day
df6 = df5b[!duplicated(df5b$datecomp),]
df6b = df5b[duplicated(df5b$datecomp),]
# Combine df45 (non-duplicated rows of 1, 2, 3, 4 or 5 articles per day) with df6 (non-duplicated
# rows of 6 articles per day)
df56 = full_join(df45,df6,by="datecomp")
# Split duplicated rows (df6b) into df7 (non-duplicated rows) and df7b (duplicated rows)
# This is done to take into account 7 articles per company per day
df7 = df6b[!duplicated(df6b$datecomp),]
df7b = df6b[duplicated(df6b$datecomp),]
# Combine df56 (non-duplicated rows of 1, 2, 3, 4, 5 or 6 articles per day) with df7 (non-duplicated
# rows of 7 articles per day)
df67 = full_join(df56,df7,by="datecomp")
# Split duplicated rows (df7b) into df8 (non-duplicated rows) and df8b (duplicated rows)
# This is done to take into account 8 articles per company per day
df8 = df7b[!duplicated(df7b$datecomp),]
df8b = df7b[duplicated(df7b$datecomp),]
# Combine df67 (non-duplicated rows of 1, 2, 3, 4, 5, 6 or 7 articles per day) with df8 (non-duplicated
# rows of 8 articles per day)
df78 = full_join(df67,df8,by="datecomp")
# Split duplicated rows (df8b) into df9 (non-duplicated rows) and df9b (duplicated rows)
# This is done to take into account 9 articles per company per day
df9 = df8b[!duplicated(df8b$datecomp),]
df9b = df8b[duplicated(df8b$datecomp),]
# Combine df78 (non-duplicated rows of 1, 2, 3, 4, 5, 6, 7 or 8 articles per day) with df9 (non-duplicated
# rows of 9 articles per day)
df89 = full_join(df78,df9,by="datecomp")
# Are there still duplicate dates?
length(which(duplicated(df9b$datecomp)==TRUE))    # We have reached the end
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x) %>%
str_replace_all("NA", "")
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x)
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
end.df$text <- str_remove_all(NA)
end.df$text <- str_remove_all(end.df$text, "NA")
View(end.df)
end.df$text[1]
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x)
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
end.df$text[1]
end.df$text <- str_remove_all(end.df$text, "NA")
end.df$text[1]
library(ISLR2)
attach(Weekly)
summary(Weekly)
summary(lm(Volume~., data = Weekly))
plot(Weekly)
plot(Volume~., data = Weekly)
par(mfrow = c(4,4))
plot(Volume~., data = Weekly)
par(mfrow = c(6,2))
plot(Volume~., data = Weekly)
par(mfrow = c(5,3))
plot(Volume~., data = Weekly)
par(mfrow = c(4,4))
plot(Volume~., data = Weekly)
graphics.off()
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
summary(logreg)
n <- nrow(Weekly)
n <- nrow(Weekly)/2
train <- Weekly[1:4755]
train <- Weekly[,1:4755]
train <- Weekly[,1:545]
train <- Weekly[,1:n]
train <- Weekly[1:n,]
test <- Weekly[-1:n,]
test <- Weekly[-test,]
test <- Weekly[-train,]
train <- Weekly *80%
train <- Weekly * 0.8
table(Weekly$Direction, pred > 0.5)
pred <- predict(logreg, type "response")
table(Weekly$Direction, pred > 0.5)
pred <- predict(logreg, type = "response")
table(Weekly$Direction, pred > 0.5)
sum(diag(conf.mat))/sum(conf.mat)
pred <- predict(logreg, type = "response")
conf.mat <- table(Weekly$Direction, pred > 0.5)
conf.mat
sum(diag(conf.mat))/sum(conf.mat)
ind <- Weekly$Year<=2008
train <- Weekly[ind,]
test <- Weekly[!ind,]
logreg2 <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = train,
family = "binomial")
pred2 <- predict(logreg2, test, type = "response")
conf.mat2 <- table(Weekly$Direction, pred2 > 0.5)
conf.mat2
sum(diag(conf.mat2))/sum(conf.mat2)
conf.mat2 <- table(test$Direction, pred2 > 0.5)
conf.mat2
sum(diag(conf.mat2))/sum(conf.mat2)
library(MASS)
ldareg <- lda(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = train)
ldareg <- lda(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = train)
pred3 <- predict(ldareg, test, type = "response")
conf.mat3 <- table(test$Direction, pred3 > 0.5)
conf.mat3
sum(diag(conf.mat3))/sum(conf.mat3)
conf.mat3 <- table(test$Direction, pred3$class)
conf.mat3
sum(diag(conf.mat3))/sum(conf.mat3)
qdareg <- qda(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = train)
pred4 <- predict(qdareg, test)
conf.mat4 <- table(test$Direction, pred4$class)
conf.mat4
sum(diag(conf.mat4))/sum(conf.mat4)
logreg2 <- glm(Direction~Lag2, data = train,
family = "binomial")
pred2 <- predict(logreg2, test, type = "response")
conf.mat2 <- table(test$Direction, pred2 > 0.5)
conf.mat2
sum(diag(conf.mat2))/sum(conf.mat2)
ldareg <- lda(Direction~Lag2, data = train)
pred3 <- predict(ldareg, test)
conf.mat3 <- table(test$Direction, pred3$class)
conf.mat3
sum(diag(conf.mat3))/sum(conf.mat3)
qdareg <- qda(Direction~Lag2, data = train)
pred4 <- predict(qdareg, test)
conf.mat4 <- table(test$Direction, pred4$class)
conf.mat4
sum(diag(conf.mat4))/sum(conf.mat4)
library(class)
pred5 <- knn(as.matrix(train$Lag2), as.matrix(test$Lag2), train$Direction, k=1)
conf.mat5 <- table(test$Direction, pred5)
conf.mat5
sum(diag(conf.mat5))/sum(conf.mat5)
summary(lm(Direction~., data = Weekly))
summary(lm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly))
lm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly)
lmreg <- lm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly)
summary(lmreg)
lmreg <- lm(as.numeric(Direction)~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly)
summary(lmreg)
help(Weekly)
plot(as.numeric(Direction)~., data = Weekly)
plot(Direction~., data = Weekly)
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
summary(logreg)
Weekly$Direction <- as.numeric(Weekly$Direction)
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
View(Weekly)
Weekly$Direction <- as.numeric(Weekly$Direction) -1
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
plot.ts(Weekly)
plot.ts(Direction~., data = Weekly)
View(Weekly)
Weekly$Direction <- as.numeric(Weekly$Direction) -1
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
View(Weekly)
attach(Weekly)
View(Weekly)
Weekly <- Weekly
View(Weekly)
Weekly <- Weekly
View(Weekly)
Weekly$Direction <- as.numeric(Weekly$Direction)
Weekly$Direction <- as.numeric(Weekly$Direction) -1
logreg <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Weekly,
family = "binomial")
summary(logreg)
pred <- predict(logreg, type = "response")
conf.mat <- table(Weekly$Direction, pred > 0.5)
conf.mat
sum(diag(conf.mat))/sum(conf.mat)
pred3$class
ldareg <- lda(Direction~Lag2, data = train)
ind <- Weekly$Year<=2008
train <- Weekly[ind,]
test <- Weekly[!ind,]
ldareg <- lda(Direction~Lag2, data = train)
pred3 <- predict(ldareg, test)
pred3$class
pred3$posterior
pred3$x
conf.mat3 <- table(test$Direction, pred3$class)
conf.mat3
sum(diag(conf.mat3))/sum(conf.mat3)
load("LMNorsk.RData")
View(LM.norsk)
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
# Libraries
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(stopwords)
library(lubridate)
library(RCurl)
library(dplyr)
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
