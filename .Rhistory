pattern = comp.df$companies[i])==TRUE,
1,NA)    # If company i is not detected in the "articles" string ,
}
# Remove companies that are never mentioned from the "companies" list
comp.df.new = na.omit(comp.df)
load("text.RData")
# Remove HTML code and everything but letters (not completely finished)
text <- text %>%
str_remove_all("class.*?\\n") %>%
str_remove_all("<span.*?p>") %>%
str_remove_all("<a.*?>") %>%
str_remove_all("class=\"carousel__item-txt carousel--jobbsearch-narrow__item-txt") %>%
str_remove_all("<aside.*?<\\aside") %>%
str_replace_all("<p", " ") %>%
str_replace_all("</p>", " ") %>%
str_replace_all("\n", " ") %>%
str_replace_all("[^[[:alpha:]][[:space:]]]", " ")
# Make a data frame with dates, URLs and text from each article
text = as.data.frame(text)
text$date = as.Date(date.list, "%d.%m.%Y")
text$url = url.list
# Extract URLs and dates for each article
articles <- 1
url.list <- as.character()
date.list <- as.character()
files = sort(list.files(pattern="\\.(html)$"), decreasing = T) # get list of .html files
for (file in files) {
URLs <- read_html(file) %>% # find URLs for each article
html_nodes("h3") %>%
html_nodes("a") %>%
html_attr("href")
Dates <- read_html(file) %>%
html_nodes("time") %>% # find dates for each article
html_attr("datetime")
url.list <- append(url.list, URLs)
date.list <- append(date.list, Dates)
}
# Are there duplicate urls?
nrow((distinct(as.data.frame(url.list))))
which(duplicated(url.list) == TRUE)
# Removing wrong/not working URLs)
grep("notis", url.list)
grep("https://www.dn.no/marked/2-1-", url.list)
grep("https://www.dn.no/arbeidsliv/2-1", url.list)
grep("https://www.dn.no/personvern/handel/slar-alarm-om-personvern/1-1-5397744", url.list)
grep("https://www.dn.no/borsbarna/finans/mener-aksjer-larer-ungene-om-frykt-og-gradighet/1-1-5331779", url.list)
grep("https://www.dn.no/dagligvare/handel/coop-vil-selge-103-butikker/1-1-5308961", url.list)
# Log in to DN subscription
# Only run after having closed R/cleaned environment!
url <- "https://www.dn.no/auth/login"
uastring <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36"
session <- session(url, user_agent(uastring))
form <- html_form(session)[[1]]
fill <- html_form_set(form,
username = "livewt@live.no",
password = "masterthesis123")
session_submit(session, fill, submit = NULL, config(referer = session$url))
# Extract text from each article
text <- list()
for (url in url.list) {
jump <- session %>%
session_jump_to(url)  # Jump to each URL logged in
html <- read_html(jump) %>%
html_nodes("article") %>%
html_nodes("section") %>%
html_nodes("p")
text <- rbind(text, toString(html))
}
# Remove HTML code and everything but letters (not completely finished)
text <- text %>%
str_remove_all("class.*?\\n") %>%
str_remove_all("<span.*?p>") %>%
str_remove_all("<a.*?>") %>%
str_remove_all("class=\"carousel__item-txt carousel--jobbsearch-narrow__item-txt") %>%
str_remove_all("<aside.*?<\\aside") %>%
str_replace_all("<p", " ") %>%
str_replace_all("</p>", " ") %>%
str_replace_all("\n", " ") %>%
str_replace_all("[^[[:alpha:]][[:space:]]]", " ")
# Make a data frame with dates, URLs and text from each article
text = as.data.frame(text)
text$date = as.Date(date.list, "%d.%m.%Y")
text$url = url.list
names(text)[1] <- "text"
# Remove duplicated text
which(duplicated(text$text))
load("text.Rdata")
# Remove HTML code and everything but letters (not completely finished)
text <- text %>%
str_remove_all("class.*?\\n") %>%
str_remove_all("<span.*?p>") %>%
str_remove_all("<a.*?>") %>%
str_remove_all("class=\"carousel__item-txt carousel--jobbsearch-narrow__item-txt") %>%
str_remove_all("<aside.*?<\\aside") %>%
str_replace_all("<p", " ") %>%
str_replace_all("</p>", " ") %>%
str_replace_all("\n", " ") %>%
str_replace_all("[^[[:alpha:]][[:space:]]]", " ")
# Make a data frame with dates, URLs and text from each article
text = as.data.frame(text)
text$date = as.Date(date.list, "%d.%m.%Y")
text$url = url.list
names(text)[1] <- "text"
# Remove duplicated text
which(duplicated(text$text))
text <- text[!duplicated(text$text), ]
text$date = as.Date(date.list, "%d.%m.%Y")
text$url = url.list
for (file in files) {
URLs <- read_html(file) %>% # find URLs for each article
html_nodes("h3") %>%
html_nodes("a") %>%
html_attr("href")
Dates <- read_html(file) %>%
html_nodes("time") %>% # find dates for each article
html_attr("datetime")
url.list <- append(url.list, URLs)
date.list <- append(date.list, Dates)
}
# Are there duplicate urls?
nrow((distinct(as.data.frame(url.list))))
which(duplicated(url.list) == TRUE)
setwd("C:/Users/Herdis/Desktop/thesis")
# Extract URLs and dates for each article
articles <- 1
url.list <- as.character()
date.list <- as.character()
files = sort(list.files(pattern="\\.(html)$"), decreasing = T) # get list of .html files
for (file in files) {
URLs <- read_html(file) %>% # find URLs for each article
html_nodes("h3") %>%
html_nodes("a") %>%
html_attr("href")
Dates <- read_html(file) %>%
html_nodes("time") %>% # find dates for each article
html_attr("datetime")
url.list <- append(url.list, URLs)
date.list <- append(date.list, Dates)
}
# Are there duplicate urls?
nrow((distinct(as.data.frame(url.list))))
which(duplicated(url.list) == TRUE)
# Removing wrong/not working URLs)
grep("notis", url.list)
grep("https://www.dn.no/marked/2-1-", url.list)
grep("https://www.dn.no/arbeidsliv/2-1", url.list)
grep("https://www.dn.no/personvern/handel/slar-alarm-om-personvern/1-1-5397744", url.list)
grep("https://www.dn.no/borsbarna/finans/mener-aksjer-larer-ungene-om-frykt-og-gradighet/1-1-5331779", url.list)
grep("https://www.dn.no/dagligvare/handel/coop-vil-selge-103-butikker/1-1-5308961", url.list)
url.list <- url.list[-c(500, 1015, 1016, 4709, 4728, 4819, 5290, 5551, 5655, 5812, 6029, 6042, 6077, 7125, 10823, 15118, 15802, 16111)]
date.list <- date.list[-c(500, 1015, 1016, 4709, 4728, 4819, 5290, 5551, 5655, 5812, 6029, 6042, 6077, 7125, 10823, 15118, 15802, 16111)]
# Extract text from each article
text <- list()
load("text.RData")
# Remove HTML code and everything but letters (not completely finished)
text <- text %>%
str_remove_all("class.*?\\n") %>%
str_remove_all("<span.*?p>") %>%
str_remove_all("<a.*?>") %>%
str_remove_all("class=\"carousel__item-txt carousel--jobbsearch-narrow__item-txt") %>%
str_remove_all("<aside.*?<\\aside") %>%
str_replace_all("<p", " ") %>%
str_replace_all("</p>", " ") %>%
str_replace_all("\n", " ") %>%
str_replace_all("[^[[:alpha:]][[:space:]]]", " ")
# Make a data frame with dates, URLs and text from each article
text = as.data.frame(text)
# Start here
rm(list = ls())
load("text.Rdata")
load("stocks.Rdata")
# Get the names of the companies we have stock price data for
companies = unique(stocks$Company)
# Add Statoil to companies
companies = c(companies,"Statoil")
# 1. Which companies are never mentioned?
# Create data frame with "companies" column and "mentioned" column
comp.df = data.frame(companies,"mentioned" = 0)
# Create string with text from all articles (easier to search in than in each row)
articles = toString(text$text)   # Takes a minute or two
# Loop: for i in each row of comp.df, assign 1 to the "mentioned" column if a
# company name is found in the "articles" string and 0 if not
for(i in 1:nrow(comp.df)){
comp.df$mentioned[i] =
ifelse(str_detect(string = articles,
pattern = comp.df$companies[i])==TRUE,
1,NA)    # If company i is not detected in the "articles" string ,
}
# Remove companies that are never mentioned from the "companies" list
comp.df.new = na.omit(comp.df)
# Create new list with company names that are mentioned
companies = comp.df.new$companies
# New column in text data frame for company names
text$Company <- ""
# Loop to paste company names into new Company column
for (company in 1:length(companies)) {
for (t in 1:length(text$text)) {
if (grepl(companies[company], text[t,1], fixed = TRUE)) {
m <- gregexpr(companies[company], text[t,1])
ct <- text[t,4]
name <- toString(regmatches(text[t,1], m)[[1]])
name <- gsub(" ", "-", name)
text[t,4] <- paste(ct, name, sep = ", ")
}
akastor = stocks %>% filter(Company=="Akastor")
View(akastor)
max(akastor$date)
akersolutions = stocks %>% filter(Company=="Aker Solutions")
View(akersolutions)
max(akersolutions$date)
aker.akastor = full_join(akersolutions,akastor,by="date")
View(aker.akastor)
text <- text[!text$Company=="",] # Remove rows with no company names
# Loop to remove company names that only get mentioned once per article
for (t in 1:length(text$Company)) {
for (c in companies) {
if (str_count(text[t,4], c) <= 1) {
text[t,4] <- gsub(c, "", text[t,4])
}
# Remove rows where only companies were mentioned once and commas
text$Company <- str_replace_all(text$Company, ",", " ")
text$Company <- gsub("^[[:space:]]+$", NA, text$Company)
text <- text[!(is.na(text$Company)),]
# Loop to choose the most mentioned company for each article
for (t in 1:length(text$Company)) {
for (c in companies) {
words <- strsplit(text[t,4], "[[:space:]]+")[[1]]
most <- tail(sort(words), 1)
text[t,4] <- text[t,4] %>% gsub(text[t,4], "", text[t,4]) %>%
gsub("", most, text[t,4])
}
text$Company <- gsub("-", " ", text$Company)
df <- merge(text, stocks, by=c("date","Company")) # Merge text and stocks df's
df.new = df
df.new$datecomp = paste0(df.new$date," ", df.new$Company)
nrow(distinct(df.new$datecomp))
nrow(unique(df.new$datecomp))
View(df.new)
duplicated(df.new$datecomp)
datecomp = df.new$datecomp
datecomp = datecomp[!duplicated(datecomp)]
datecomp = df.new$datecomp
datecomp = datecomp[!duplicated(datecomp)]
df.new$datecomp = paste0(df.new$date," ", df.new$Company)
datecomp = df.new$datecomp
datecomp = as.data.frame(datecomp[!duplicated(datecomp)])
View(datecomp)
datecomp = as.data.frame(datecomp[!duplicated(datecomp)],
colnames = "datecomp")
datecomp = as.data.frame(datecomp[!duplicated(datecomp)]) %>%
names(datecomp) = "datecomp"
datecomp = paste0(df$date," ", df$Company)
View(text)
# Create data frame with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(df$date, df$Company)
# Create data frame with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
datecomp = text$datecomp[!duplicated(text$datecomp)]
datecomp = as.data.frame(text$datecomp[!duplicated(text$datecomp)])
View(datecomp)
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
datecomp = as.data.frame(text$datecomp[duplicated(text$datecomp)])
View(datecomp)
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
datecomp = as.data.frame(text$datecomp[duplicated(text$datecomp)])
View(datecomp)
duplicated(datecomp)
View(text)
text$datecomp = paste(text$date, text$Company)
datecomp = as.data.frame("datecomp" = text$datecomp[duplicated(text$datecomp)],
text)
View(datecomp)
datecomp = as.data.frame("datecomp" = text$datecomp[duplicated(text$datecomp)])
datecomp = data.frame("datecomp" = text$datecomp[duplicated(text$datecomp)])
View(datecomp)
nrow(duplicates(datecomp))
nrow(duplicated(datecomp))
which(duplicated(text$datecomp) == TRUE)
# Create object with duplicates (more than one article on the same day about the
# same company)
nrow(which(duplicated(text$datecomp) == TRUE))
# Create object with duplicates (more than one article on the same day about the
# same company)
length(which(duplicated(text$datecomp) == TRUE))
datecomp = text$datecomp[duplicated(text$datecomp),]
datecomp = text[duplicated(text$datecomp),]
View(datecomp)
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
View(datecomp)
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# For some reason not all articles in datecomp are true duplicates:
length(which(duplicated(datecomp$datecomp) == TRUE))
datecomp = datecomp[duplicated(datecomp$datecomp),]
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
length(which(duplicated(text$datecomp) == TRUE))
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
length(which(duplicated(text$datecomp) == TRUE))
datecomp = text[duplicated(text$datecomp),]
View(datecomp)
# Are there duplicate urls?
nrow((distinct(as.data.frame(url.list))))
datecomp[3,]
datecomp[3,5]
text$datecomp = paste(text$date, text$Company)
length(which(duplicated(text$datecomp) == TRUE))
datecomp = text[!duplicated(text$datecomp),]
View(datecomp)
length(which(duplicated(datecomp$datecomp)==TRUE))
datecomp = text[duplicated(text$datecomp),]
length(which(duplicated(datecomp$datecomp)==TRUE))
text$datecomp = paste(text$date, text$Company)
length(which(duplicated(text$datecomp) == TRUE))
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
df1 = text[!duplicated(text$datecomp),]
df2 = text[duplicated(text$datecomp),]
nrow(df1)+nrow(df2)-nrow(text)
df_1 <- data_frame(
dates = c(as.Date("2018-07-01"), as.Date("2018-06-01"), as.Date("2018-06-01"), as.Date("2018-05-01")),
x1 = c(10L, 11L, 12L, 13L),
text1 = c("text a", "text b", "text c", "text d")
)
df_2 <- data_frame(
dates = c(as.Date("2018-07-01"), as.Date("2018-06-01"), as.Date("2018-05-01"), as.Date("2018-04-01")),
x2 = c(20L, 21L, 22L, 23L),
text2 = c("text aa", "text bb", "text cc", "text dd")
)
df_1
df_2
left_join(df_1 %>% group_by(dates) %>% mutate(id = row_number()),
df_2 %>% group_by(dates) %>% mutate(id = row_number()),
by = c("dates", "id"))
View(df_1)
View(df1)
# Split text data frame into df1 (non-duplicated rows) and d2 (duplicated rows)
df1 = text[!duplicated(text$datecomp),] %>%
select(datecomp,text)
df2 = text[duplicated(text$datecomp),] %>%
select(datecomp,text)
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
# Split text data frame into df1 (non-duplicated rows) and d2 (duplicated rows)
df1 = text[!duplicated(text$datecomp),] %>%
select(datecomp,text)
df2 = text[duplicated(text$datecomp),] %>%
select(datecomp,text)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
by = c("datecomp","id")
left_join(df1 %>% group_by(datecomp) %>% mutate(id = row_number()),
df2 %>% group_by(datecomp) %>% mutate(id = row_number()),
by = c("datecomp","id")
left_join(df1 %>% group_by(datecomp) %>% mutate(id = row_number()),
df2 %>% group_by(datecomp) %>% mutate(id = row_number()),
by = c("datecomp","id"))
tail(left_join(df1 %>% group_by(datecomp) %>% mutate(id = row_number()),
df2 %>% group_by(datecomp) %>% mutate(id = row_number()),
by = c("datecomp","id")))
test = left_join(df1 %>% group_by(datecomp) %>% mutate(id = row_number()),
df2 %>% group_by(datecomp) %>% mutate(id = row_number()),
by = c("datecomp","id"))
View(test)
companies
duplicated(df1)
duplicated(df2)
which(duplicated(df2)==TRUE)
which(duplicated(df1)==TRUE)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
View(df2)
which(duplicated(df1$datecomp)==TRUE)
which(duplicated(df2$datecomp)==TRUE)
text[,1]
View(df2)
for(t in 1:nrow(text)){
if(text$datecomp[t] == text$datecomp[t+1]){
text$text[t] = paste0(text[t]," ",text[t+1])
text = text[-c(t+1),]
}
for(t in 1:nrow(text)){
if(text$datecomp[t] == text$datecomp[t+1]){
text$text[t] = paste0(text[t]," ",text[t+1])
}
for(t in 1:nrow(text)){
if(text$datecomp[t] == text$datecomp[t+1]){
text$text[t] = paste0(text$text[t]," ",text$text[t+1])
}
for(t in 1:nrow(text)){
if((text$datecomp[t] == text$datecomp[t+1])==TRUE){
text$text[t] = paste0(text$text[t]," ",text$text[t+1])
}
text2 = text %>%
select(datecomp,text)
head(text2)
# Trying something
text$datecomp = paste(text$date, text$Company)
text2 = text %>%
select(datecomp,text)
ddply(text,"datecomp",numcolwise(sum))
View(df1)
df3 = full_join(d1,d2,by="datecomp")
df3 = full_join(df1,df2,by="datecomp")
nrow(df3)-nrow(text)
duplicated(df3)
View(df3)
df3 = na.omit(df3)
View(df3)
df3 = text[duplicated(df2$datecomp),]
df3 = df2[duplicated(df2$datecomp),]
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)+nrow(df3)-nrow(text)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
# Combine
df3 = full_join(d1,d2,by="datecomp")
# Create object with duplicates (more than one article on the same day about the
# same company)
text$datecomp = paste(text$date, text$Company)
text2 = text %>%
select(datecomp,text)
# Split text data frame into df1 (non-duplicated rows) and d2 (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),] %>%
select(datecomp,text)
df2 = text2[duplicated(text2$datecomp),] %>%
select(datecomp,text)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
# Combine
df3 = full_join(df1,df2,by="datecomp")
df3 = na.omit(df3)
df3. = left_join(df1,df2,by="datecomp")
# Are there still duplicate dates?
length(which(duplicated(df3$datecomp)==TRUE))
# Repeat steps above: Split df3 data frame into df3a (non-duplicated rows) and df3b (duplicated rows)
df3a = df3[!duplicated(df3$datecomp),]
df3b = df3[duplicated(text2$datecomp),]
# Are there still duplicate dates?
length(which(duplicated(df3b$datecomp)==TRUE))
# Combine
df4 = full_join(df3a,df3b,by="datecomp")
View(df4)
df4 = na.omit(df4)
View(df4)
# Combine
df4 = full_join(df3a,df3b,by="datecomp")
text$datecomp = paste(text$date, text$Company)
text2 = text %>%
select(datecomp,text)
# Split text data frame into df1 (non-duplicated rows) and d2 (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),] %>%
select(datecomp,text)
df2 = text2[duplicated(text2$datecomp),] %>%
select(datecomp,text)
# Check that all rows have been assigned to either d1 or d2
nrow(df1)+nrow(df2)-nrow(text)
# Combine
df3 = full_join(df1,df2,by="datecomp")
df3 = na.omit(df3)
# Are there still duplicate dates?
length(which(duplicated(df3$datecomp)==TRUE))
# Repeat steps above: Split df3 data frame into df3a (non-duplicated rows) and df3b (duplicated rows)
df3a = df3[!duplicated(df3$datecomp),]
df3b = df3[duplicated(text2$datecomp),]
# Combine
df4 = full_join(df3a,df3b,by="datecomp")
df4 = na.omit(df4)
# Repeat
df5a = df4[!duplicated(df4$datecomp),]
df5b = df4[duplicated(df4$datecomp),]
# Combine
df5 = full_join(df5a,df5b,by="datecomp")
df5 = na.omit(df5)
length(which(duplicated(df5$datecomp)==TRUE))
# Repeat
df6a = df5[!duplicated(df5$datecomp),]
df6b = df5[duplicated(df5$datecomp),]
# Combine
df6 = full_join(df5,df6,by="datecomp")
# Combine
df6 = full_join(df6a,df6b,by="datecomp")
df6 = na.omit(df6)
length(which(duplicated(df6$datecomp)==TRUE))
