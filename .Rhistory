# Loop to choose the most mentioned company for each article
for (t in 1:length(text$Company)) {
for (c in companies) {
words <- strsplit(text[t,4], "[[:space:]]+")[[1]]
most <- names(sort(table(words), decreasing = TRUE))[1]
text[t,4] <- text[t,4] %>% gsub(text[t,4], "", text[t,4]) %>%
gsub("", most, text[t,4])
}
# Replace - with spaces and remove spaces before company names
text$Company <-  text$Company %>%
gsub("-", " ",.) %>%
gsub("^[[:space:]]+", "",.)
# Change old company names to new company names
text$Company <- text$Company %>%
gsub("statoil", "equinor", .) %>%
gsub("marine harvest", "mowi", .) %>%
gsub("pgs", "petroleum geo services", .) %>%
gsub("noreco", "norwegian energy company", .) %>%
gsub("af group","af gruppen",.) %>%
gsub("solstad farstad","solstad offshore",.) %>%
gsub("vekselbanken","voss veksel og landmandsbank",.) %>%
gsub("bergen group", "endúr", .) %>%
gsub("vardia insurance","insr insurance",.) %>%
gsub("skandiabanken","sbanken",.) %>%
gsub("psi", "strongpoint", .) %>%
gsub("opera software","otello",.) %>%
gsub("apptix", "carasent", .) %>%
gsub("tts group","nekkar",.) %>%
gsub("namsos trafikkselskap", "nts group", .)
# Create row with date and company to identify instances where there are more than 1
# article about a company on a specific date:
text$datecomp = paste(text$date, text$Company)
# Select relevant columns
text2 = text %>%
select(datecomp,text,date,Company) %>%
group_by(datecomp)
# Split text data frame into df1 (non-duplicated rows) and d1b (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),]
df1b = text2[duplicated(text2$datecomp),]
# Check that all rows have been assigned to either d1 or d1b
nrow(df1)+nrow(df1b)-nrow(text)
# Split duplicated rows (d1fb) into df2 (non-duplicated rows) and df2b (duplicated rows)
# This is done to take into account 2 articles per company per day
df2 = df1b[!duplicated(df1b$datecomp),]
df2b = df1b[duplicated(df1b$datecomp),]
# Combine df1 (non-duplicated rows of 1 article per day) with df2 (non-duplicated
# rows of 2 articles per day)
df12 = full_join(df1,df2,by="datecomp")
# Split duplicated rows (df2b) into df3 (non-duplicated rows) and df3b (duplicated rows)
# This is done to take into account 3 articles per company per day
df3 = df2b[!duplicated(df2b$datecomp),]
df3b = df2b[duplicated(df2b$datecomp),]
# Combine df12 (non-duplicated rows of 1 or 2 articles per day) with df3 (non-duplicated
# rows of 3 articles per day)
df23 = full_join(df12,df3,by="datecomp")
# Split duplicated rows (df3b) into df4 (non-duplicated rows) and df4b (duplicated rows)
# This is done to take into account 4 articles per company per day
df4 = df3b[!duplicated(df3b$datecomp),]
df4b = df3b[duplicated(df3b$datecomp),]
# Combine df23 (non-duplicated rows of 1, 2 or 3 articles per day) with df4 (non-duplicated
# rows of 4 articles per day)
df34 = full_join(df23,df4,by="datecomp")
# Split duplicated rows (df4b) into df5 (non-duplicated rows) and df5b (duplicated rows)
# This is done to take into account 5 articles per company per day
df5 = df4b[!duplicated(df4b$datecomp),]
df5b = df4b[duplicated(df4b$datecomp),]
# Combine df34 (non-duplicated rows of 1, 2, 3 or 4 articles per day) with df5 (non-duplicated
# rows of 5 articles per day)
df45 = full_join(df34,df5,by="datecomp")
# Split duplicated rows (df5b) into df6 (non-duplicated rows) and df6b (duplicated rows)
# This is done to take into account 6 articles per company per day
df6 = df5b[!duplicated(df5b$datecomp),]
df6b = df5b[duplicated(df5b$datecomp),]
# Combine df45 (non-duplicated rows of 1, 2, 3, 4 or 5 articles per day) with df6 (non-duplicated
# rows of 6 articles per day)
df56 = full_join(df45,df6,by="datecomp")
# Split duplicated rows (df6b) into df7 (non-duplicated rows) and df7b (duplicated rows)
# This is done to take into account 7 articles per company per day
df7 = df6b[!duplicated(df6b$datecomp),]
df7b = df6b[duplicated(df6b$datecomp),]
# Combine df56 (non-duplicated rows of 1, 2, 3, 4, 5 or 6 articles per day) with df7 (non-duplicated
# rows of 7 articles per day)
df67 = full_join(df56,df7,by="datecomp")
# Split duplicated rows (df7b) into df8 (non-duplicated rows) and df8b (duplicated rows)
# This is done to take into account 8 articles per company per day
df8 = df7b[!duplicated(df7b$datecomp),]
df8b = df7b[duplicated(df7b$datecomp),]
# Combine df67 (non-duplicated rows of 1, 2, 3, 4, 5, 6 or 7 articles per day) with df8 (non-duplicated
# rows of 8 articles per day)
df78 = full_join(df67,df8,by="datecomp")
# Split duplicated rows (df8b) into df9 (non-duplicated rows) and df9b (duplicated rows)
# This is done to take into account 9 articles per company per day
df9 = df8b[!duplicated(df8b$datecomp),]
df9b = df8b[duplicated(df8b$datecomp),]
# Combine df78 (non-duplicated rows of 1, 2, 3, 4, 5, 6, 7 or 8 articles per day) with df9 (non-duplicated
# rows of 9 articles per day)
df89 = full_join(df78,df9,by="datecomp")
# Are there still duplicate dates?
length(which(duplicated(df9b$datecomp)==TRUE))    # We have reached the end
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x)
# Change date: date + 1
df.end$date <- as.Date(df.end$date) +1
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
# Remove NA at end of text
end.df$text <- str_remove_all(end.df$text, "NA")
# Remove all my unnecessary dfs
rm(list = ls(pattern = "^df"))
# Remove NAs
end.df$text = na.omit(end.df$text)
# Final data frame is "df"
df = end.df
# Libraries
library(readxl)
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(lubridate)
library(RCurl)
library(dplyr)
library(tm)
library(stopwords)
library(quanteda)
library(boot)
library(e1071)
library(ROCR)
library(caret)
library(class)
library(gam)
library(tree)
library(randomForest)
# STOCK PRICE RETRIEVAL
# List of all registered companies
# Get list of all .xlsx files
file.list = list.files(pattern='*.xlsx')
# Read all files
y2014 = read_excel(path = file.list[1], skip = 9)   # Read 2014 file
y2014 = rbind(y2014[1:25,],    # OBX
y2014[29:150,],  # OB Match
y2014[155:185,]) # OB Standard and New
y2015 = read_excel(path = file.list[2], skip = 9)   # Read 2015 file
y2015 = rbind(y2015[1:25,],    # OBX
y2015[29:148,],  # OB Match
y2015[153:181,]) # OB Standard and New
y2016 = read_excel(path = file.list[3], skip = 9)   # Read 2016 file
y2016 = rbind(y2016[1:25,],    # OBX
y2016[29:151,],  # OB Match
y2016[155:180,]) # OB Standard and New
y2017 = read_excel(path = file.list[4], skip = 9)   # Read 2017 file
y2017 = rbind(y2017[1:25,],    # OBX
y2017[28:163,],  # OB Match
y2017[167:187,]) # OB Standard and New
y2018 = read_excel(path = file.list[5], skip = 9)   # Read 2018 file
y2018 = rbind(y2018[1:25,],    # OBX
y2018[28:158,],  # OB Match
y2018[162:186,]) # OB Standard and New
y2019 = read_excel(path = file.list[6], skip = 9)   # Read 2019 file
y2019 = rbind(y2019[1:25,],    # OBX
y2019[28:162,],  # OB Match
y2019[166:188,]) # OB Standard and New
# Combine
all.firms = rbind(y2014,y2015,y2016,y2017,y2018,y2019)
# Select relevant columns
all.firms =
all.firms %>%
select("Company" = OBX, ticker = ...20)
# Find unique company names
all.firms = all.firms[!duplicated(all.firms$ticker),]
# Remove 'y20XX' data frames
rm(list = ls(pattern = "^y20"))
# Manually rename wrong tickers
all.firms$ticker =
all.firms$ticker %>%
gsub("AKERBP","AKRBP",.) %>%
gsub("AKA","AKAST",.) %>%
gsub("ARCHER","ARCH",.) %>%
gsub("ASETEK","ASTK",.) %>%
gsub("AVANCE","AGAS",.) %>%
gsub("BEL","BELCO",.) %>%
gsub("BON","BONHR",.) %>%
gsub("BDRILL","BORR",.) %>%
gsub("BOUVET","BOUV",.) %>%
gsub("COV","CONTX",.) %>%
gsub("CRAYON","CRAYN",.) %>%
gsub("FKRAFT","FKRFT",.) %>%
gsub("NANO","NANOV",.) %>%
gsub("PROTCT","PROT",.) %>%
gsub("REC","RECSI",.) %>%
gsub("SALMON","SACAM",.) %>%
gsub("SBX","GEG",.) %>%
gsub("WWASA","WWI",.) %>%
gsub("STRONG","STRO",.) %>%
gsub("VISTIN","VISTN",.) %>%
gsub("ASC","ABG",.) %>%
gsub("AXA","ACR",.) %>%
gsub("NORBIT","NORBT",.) %>%
gsub("OTELLO","OTEC",.) %>%
gsub("SAS NOK","SASNO",.) %>%
gsub("SSO","SCATC",.) %>%
gsub("ULTIMO","ULTI",.) %>%
gsub("WALWIL","WAWI",.) %>%
gsub("SCH","SCHA",.) %>%
gsub("WBULK","WEST",.)
# Edit ticker to be on the format "TICKER.OL"
all.firms$ticker = paste0(all.firms$ticker, ".OL")
# Create vector of tickers
all.tickers = as.vector(all.firms$ticker)
# Manually change company names to their more "referred-to" versions
# (Yara international becomes Yara, etc.), remove "," and "."
all.firms$Company =
all.firms$Company %>%
gsub("Norwegian Air Shuttle", "Norwegian Air",.) %>%
gsub("Yara International","Yara",.) %>%
gsub("AKVA Group", "AKVA",.) %>%
gsub("ABG Sundal Collier Holding","ABG Sundal Collier",.) %>%
gsub("Avance Gas Holding","Avance Gas",.) %>%
gsub("BW Offshore Limited","BW Offshore",.) %>%
gsub("Electromagnetic Geoservices", "EMGS",.) %>%
gsub("InterOil Exploration and Production","Interoil",.) %>%
gsub("Lerøy Seafood Group","Lerøy Seafood",.) %>%
gsub("Questerre Energy Corporation", "Questerre",.) %>%
gsub("SAS AB", "SAS", .) %>%
gsub("Subsea 7","Subsea",.) %>%
gsub("Petroleum Geo-Services", "Petroleum Geo Services",.) %>%
gsub("Q-Free", "Q Free",.) %>%
gsub("Tomra Systems", "Tomra",.) %>%
gsub("Voss Veksel- og Landmandsbank","Voss Veksel og Landmandsbank",.) %>%
gsub("Link Mobility Group","Link Mobility",.) %>%
gsub("Crayon Group Holding", "Crayon",.) %>%
gsub("Insr Insurance Group", "Insr Insurance",.) %>%
gsub("NEXT Biometrics Group", "Next Biometrics",.) %>%
gsub("Questerre Energy Corporation","Questerre",.) %>%
gsub("Jinhui Shipping and Transportation","Jinhui Shipping",.) %>%
gsub("TGS-NOPEC Geophysical Company","TGS Nopec",.) %>%
gsub("Golden Ocean Group","Golden Ocean",.) %>%
gsub("Otello Corporation","Otello",.) %>%
gsub("Fjordkraft Holding", "Fjordkraft", .) %>%
gsub("PCI Biotech Holding","PCI Biotech",.) %>%
gsub("S.D. Standard Drilling", "SD Standard Drilling",.) %>%
gsub("TietoEVRY","Tieto",.) %>%
gsub("Oceanteam Shipping","Oceanteam",.) %>%
gsub("Gaming Innovation Group", "Gaming Innovation",.) %>%
gsub("Panoro Energy","Panoro",.) %>%
gsub("Havyard Group","Havyard",.) %>%
gsub("American Shipping Company","American Shipping",.) %>%
gsub("Vistin Pharma", "Vistin",.) %>%
gsub("Gjensidige Forsikring","Gjensidige",.) %>%
gsub("NTS","NTS Group",.) %>%
gsub("\\.","",.) %>%
gsub("\\,","",.)
View(all.firms)
# Manually change company names to their more "referred-to" versions
# (Yara international becomes Yara, etc.), remove "," and "."
all.firms$Company =
all.firms$Company %>%
gsub("Norwegian Air Shuttle", "Norwegian Air",.) %>%
gsub("Yara International","Yara",.) %>%
gsub("AKVA Group", "AKVA",.) %>%
gsub("ABG Sundal Collier Holding","ABG Sundal Collier",.) %>%
gsub("Avance Gas Holding","Avance Gas",.) %>%
gsub("BW Offshore Limited","BW Offshore",.) %>%
gsub("Electromagnetic Geoservices", "EMGS",.) %>%
gsub("InterOil Exploration and Production","Interoil",.) %>%
gsub("Lerøy Seafood Group","Lerøy Seafood",.) %>%
gsub("Questerre Energy Corporation", "Questerre",.) %>%
gsub("SAS AB", "SAS", .) %>%
gsub("Subsea 7","Subsea",.) %>%
gsub("Petroleum Geo-Services", "Petroleum Geo Services",.) %>%
gsub("Q-Free", "Q Free",.) %>%
gsub("Tomra Systems", "Tomra",.) %>%
gsub("Voss Veksel- og Landmandsbank","Voss Veksel og Landmandsbank",.) %>%
gsub("Link Mobility Group","Link Mobility",.) %>%
gsub("Crayon Group Holding", "Crayon",.) %>%
gsub("Insr Insurance Group", "Insr Insurance",.) %>%
gsub("NEXT Biometrics Group", "Next Biometrics",.) %>%
gsub("Questerre Energy Corporation","Questerre",.) %>%
gsub("Jinhui Shipping and Transportation","Jinhui Shipping",.) %>%
gsub("TGS-NOPEC Geophysical Company","TGS Nopec",.) %>%
gsub("Golden Ocean Group","Golden Ocean",.) %>%
gsub("Otello Corporation","Otello",.) %>%
gsub("Fjordkraft Holding", "Fjordkraft", .) %>%
gsub("PCI Biotech Holding","PCI Biotech",.) %>%
gsub("S.D. Standard Drilling", "SD Standard Drilling",.) %>%
gsub("TietoEVRY","Tieto",.) %>%
gsub("Oceanteam Shipping","Oceanteam",.) %>%
gsub("Gaming Innovation Group", "Gaming Innovation",.) %>%
gsub("Panoro Energy","Panoro",.) %>%
gsub("Havyard Group","Havyard",.) %>%
gsub("American Shipping Company","American Shipping",.) %>%
gsub("Vistin Pharma", "Vistin",.) %>%
gsub("Gjensidige Forsikring","Gjensidige",.) %>%
gsub("NTS","NTS Group",.) %>%
gsub("Scatec Solar", "Scatec",.) %>%
gsub("\\.","",.) %>%
gsub("\\,","",.)
# Remove company names that sound too similar (searching for "Aker" will give
# results of "Aker" and "Aker BP" for example, "Wilh Wilhelmsen Holding"
# has both "ser A" and "ser B")
all.firms =
all.firms %>%
subset(Company != "Aker" &
Company != "Hafslund ser A" & Company != "Hafslund ser B" &
Company != "Reach Subsea" & Company != "SpareBank 1" &
Company != "Wilh Wilhelmsen Holding ser A" &
Company != "Wilh Wilhelmsen Holding ser B" &
Company != "Schibsted ser A" &
Company != "Schibsted ser B" &
Company != "Odfjell ser A" &
Company != "Odfjell ser B" &
Company != "B2Holding" &
Company != "Solstad Offshore ser B" &
Company != "Adevinta ser A")
save(stocks,file="stocks.Rdata")
rm(list = ls())
load("text.Rdata")
load("stocks.Rdata")
# Get the names of the companies we have stock price data for
companies = unique(stocks$Company)
# Add company names more used/or changed during time period
companies = c(companies,c("Statoil", "Marine Harvest",
"AF Group","Solstad Farstad",
"Vekselbanken","Bergen Group",
"Vardia Insurance",
"Skandiabanken","PSI",
"Opera Software",
"Apptix","Noreco",
"TTS Group","PGS",
"Namsos Traffikkselskap"))
# Change companies list to lowercase
companies = tolower(companies)
# Change articles to lowercase
text$text = str_to_lower(text$text)
# 1. Which companies are never mentioned?
# Create data frame with "companies" column and "mentioned" column
comp.df = data.frame(companies,"mentioned" = 0)
# Create string with text from all articles (easier to search in than in each row)
articles = toString(text$text)
# Loop: for i in each row of comp.df, assign 1 to the "mentioned" column if a
# company name is found in the "articles" string and NA if not
for(i in 1:nrow(comp.df)){
comp.df$mentioned[i] =
ifelse(str_detect(string = articles,
pattern = comp.df$companies[i])==TRUE,
1,NA)
}
# Remove companies that are never mentioned from the "companies" list
comp.df.new = na.omit(comp.df)
# Create new list with company names that are mentioned
companies = comp.df.new$companies
# New column in text data frame for company names
text$Company <- ""
# Loop to paste company names into new Company column
for (company in 1:length(companies)) {
for (t in 1:length(text$text)) {
if (grepl(companies[company], text[t,1], fixed = TRUE)) {
m <- gregexpr(companies[company], text[t,1])
ct <- text[t,4]
name <- toString(regmatches(text[t,1], m)[[1]])
name <- str_replace_all(name, " ", "-")
text[t,4] <- paste(ct, name)
}
text <- text[!text$Company=="",] # Remove rows with no company names
# Loop to remove company names that only get mentioned once per article
for (t in 1:length(text$Company)) {
for (c in companies) {
if (str_count(text[t,4], c) <= 1) {
text[t,4] <- gsub(c, "", text[t,4])
}
# Remove rows where only companies were mentioned once, commas and spaces at the start of rows
text$Company <- str_replace_all(text$Company, ",", " ")
text$Company <- text$Company %>%
gsub("^[[:space:]]+$", NA, .) %>%
gsub("^[[:space:]]+", "", .)
text <- text[!(is.na(text$Company)),]
# Loop to choose the most mentioned company for each article
for (t in 1:length(text$Company)) {
for (c in companies) {
words <- strsplit(text[t,4], "[[:space:]]+")[[1]]
most <- names(sort(table(words), decreasing = TRUE))[1]
text[t,4] <- text[t,4] %>% gsub(text[t,4], "", text[t,4]) %>%
gsub("", most, text[t,4])
}
# Replace - with spaces and remove spaces before company names
text$Company <-  text$Company %>%
gsub("-", " ",.) %>%
gsub("^[[:space:]]+", "",.)
# Change old company names to new company names
text$Company <- text$Company %>%
gsub("statoil", "equinor", .) %>%
gsub("marine harvest", "mowi", .) %>%
gsub("pgs", "petroleum geo services", .) %>%
gsub("noreco", "norwegian energy company", .) %>%
gsub("af group","af gruppen",.) %>%
gsub("solstad farstad","solstad offshore",.) %>%
gsub("vekselbanken","voss veksel og landmandsbank",.) %>%
gsub("bergen group", "endúr", .) %>%
gsub("vardia insurance","insr insurance",.) %>%
gsub("skandiabanken","sbanken",.) %>%
gsub("psi", "strongpoint", .) %>%
gsub("opera software","otello",.) %>%
gsub("apptix", "carasent", .) %>%
gsub("tts group","nekkar",.) %>%
gsub("namsos trafikkselskap", "nts group", .)
# Create row with date and company to identify instances where there are more than 1
# article about a company on a specific date:
text$datecomp = paste(text$date, text$Company)
# Select relevant columns
text2 = text %>%
select(datecomp,text,date,Company) %>%
group_by(datecomp)
# Split text data frame into df1 (non-duplicated rows) and d1b (duplicated rows)
df1 = text2[!duplicated(text2$datecomp),]
df1b = text2[duplicated(text2$datecomp),]
# Check that all rows have been assigned to either d1 or d1b
nrow(df1)+nrow(df1b)-nrow(text)
# Split duplicated rows (d1fb) into df2 (non-duplicated rows) and df2b (duplicated rows)
# This is done to take into account 2 articles per company per day
df2 = df1b[!duplicated(df1b$datecomp),]
df2b = df1b[duplicated(df1b$datecomp),]
# Combine df1 (non-duplicated rows of 1 article per day) with df2 (non-duplicated
# rows of 2 articles per day)
df12 = full_join(df1,df2,by="datecomp")
# Split duplicated rows (df2b) into df3 (non-duplicated rows) and df3b (duplicated rows)
# This is done to take into account 3 articles per company per day
df3 = df2b[!duplicated(df2b$datecomp),]
df3b = df2b[duplicated(df2b$datecomp),]
# Combine df12 (non-duplicated rows of 1 or 2 articles per day) with df3 (non-duplicated
# rows of 3 articles per day)
df23 = full_join(df12,df3,by="datecomp")
# Split duplicated rows (df3b) into df4 (non-duplicated rows) and df4b (duplicated rows)
# This is done to take into account 4 articles per company per day
df4 = df3b[!duplicated(df3b$datecomp),]
df4b = df3b[duplicated(df3b$datecomp),]
# Combine df23 (non-duplicated rows of 1, 2 or 3 articles per day) with df4 (non-duplicated
# rows of 4 articles per day)
df34 = full_join(df23,df4,by="datecomp")
# Split duplicated rows (df4b) into df5 (non-duplicated rows) and df5b (duplicated rows)
# This is done to take into account 5 articles per company per day
df5 = df4b[!duplicated(df4b$datecomp),]
df5b = df4b[duplicated(df4b$datecomp),]
# Combine df34 (non-duplicated rows of 1, 2, 3 or 4 articles per day) with df5 (non-duplicated
# rows of 5 articles per day)
df45 = full_join(df34,df5,by="datecomp")
# Split duplicated rows (df5b) into df6 (non-duplicated rows) and df6b (duplicated rows)
# This is done to take into account 6 articles per company per day
df6 = df5b[!duplicated(df5b$datecomp),]
df6b = df5b[duplicated(df5b$datecomp),]
# Combine df45 (non-duplicated rows of 1, 2, 3, 4 or 5 articles per day) with df6 (non-duplicated
# rows of 6 articles per day)
df56 = full_join(df45,df6,by="datecomp")
# Split duplicated rows (df6b) into df7 (non-duplicated rows) and df7b (duplicated rows)
# This is done to take into account 7 articles per company per day
df7 = df6b[!duplicated(df6b$datecomp),]
df7b = df6b[duplicated(df6b$datecomp),]
# Combine df56 (non-duplicated rows of 1, 2, 3, 4, 5 or 6 articles per day) with df7 (non-duplicated
# rows of 7 articles per day)
df67 = full_join(df56,df7,by="datecomp")
# Split duplicated rows (df7b) into df8 (non-duplicated rows) and df8b (duplicated rows)
# This is done to take into account 8 articles per company per day
df8 = df7b[!duplicated(df7b$datecomp),]
df8b = df7b[duplicated(df7b$datecomp),]
# Combine df67 (non-duplicated rows of 1, 2, 3, 4, 5, 6 or 7 articles per day) with df8 (non-duplicated
# rows of 8 articles per day)
df78 = full_join(df67,df8,by="datecomp")
# Split duplicated rows (df8b) into df9 (non-duplicated rows) and df9b (duplicated rows)
# This is done to take into account 9 articles per company per day
df9 = df8b[!duplicated(df8b$datecomp),]
df9b = df8b[duplicated(df8b$datecomp),]
# Combine df78 (non-duplicated rows of 1, 2, 3, 4, 5, 6, 7 or 8 articles per day) with df9 (non-duplicated
# rows of 9 articles per day)
df89 = full_join(df78,df9,by="datecomp")
# Are there still duplicate dates?
length(which(duplicated(df9b$datecomp)==TRUE))    # We have reached the end
# Combine df89 (non-duplicated rows of 1,2,3,4,5,6,7,8 or 9 articles per day)
# with df9b (final non-duplicated rows)
df.end = full_join(df89,df9b,by="datecomp")
# Combine columns (note that combining without changing NA columns results in some
# elements in the text-column end with "NA" or "NANANANANA" or something similar)
df.end =
df.end %>%
mutate("text" =
paste0(text.x,text.y,text.x.x,text.y.y,text.x.x.x,text.y.y.y,
text.x.x.x.x,text.y.y.y.y,text.x.x.x.x.x,text.y.y.y.y.y,
sep=" ")) %>%
select(datecomp,text,"date" = date.x,"Company" = Company.x)
# Change date: date + 1
df.end$date <- as.Date(df.end$date) +1
# Merge df.end with stocks by date and company
end.df <- merge(df.end, stocks, by=c("date","Company")) # Merge text and stocks df's
# Remove NA at end of text
end.df$text <- str_remove_all(end.df$text, "NA")
# Remove all my unnecessary dfs
rm(list = ls(pattern = "^df"))
# Remove NAs
end.df$text = na.omit(end.df$text)
# Final data frame is "df"
df = end.df
