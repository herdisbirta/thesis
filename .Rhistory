sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select("x" = translatedContent, y)
# SENTIMENT SCORE
# It is important that the sentiment dictionary and stopwords dictionary do not
# overlap, that would result in an unreliable sentiment score.
inner_join(data.frame(x = stopw),LM.norsk,by="x")
# Create actual sentiment score (sum of +1 and -1 values of positive/negative words
# divided by the total number of words)
score = vector()
for(t in 1:length(toks)){
score = append(score,
sum(filter(LM.norsk, x %in% toks[[t]])$y) / length(toks[[t]]))
}
# Test
sum(filter(LM.norsk, x %in% toks[[1]])$y) / length(toks[[1]]) == score[1]
sum(filter(LM.norsk, x %in% toks[[3184]])$y) / length(toks[[3184]]) == score[3184]
# Insert into df
df$sentiment = score
df <- df[!df$dir=="no change",]
# change y value to class factor
df$dir <- as.factor(df$dir)
set.seed(123)
n = nrow(df)
n.train = floor(0.8*n)
n.test = n.train+1
train = df[1:n.train,]
test = df[n.test:n,]
xtrain <- model.matrix(av.price~sentiment, train)
ytrain <- train$av.price
xtest <- model.matrix(av.price~sentiment,test)
ytest <- test$av.price
lambdamin <- cv.glmnet(xtrain,ytrain, alpha = 1, nfold = n)$lambda.min
lasso <- glmnet(xtrain, ytrain, alpha = 1, lambda = lambdamin)
lassopred <- predict(lasso, xtest)
lassomse <- mean((ytest-lassopred)^2)
conf.mat5 <- table(test$dir, lassopred)
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
accuracy5
val.set.err5 <- (conf.mat5[1,2]+conf.mat5[2,1])/(n/2)
val.set.err5
predsvmreg <- predict(svmreg, test, type = "response")
conf.mat5 <- table(test$dir, lassopred, type = "response")
conf.mat5 <- table(test$dir, lassopred, type = "response") > 0.5
conf.mat5
lambdamin <- cv.glmnet(xtrain,ytrain, alpha = 0, nfold = n)$lambda.min
lasso <- glmnet(xtrain, ytrain, alpha = 0, lambda = lambdamin)
lassopred <- predict(lasso, xtest)
conf.mat5 <- table(test$dir, lassopred)
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
accuracy5
conf.mat5 <- table(test$dir, lassopred, type = "response")
conf.mat5 <- table(test$dir, lassopred) > 0.5
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
accuracy5
val.set.err5 <- (conf.mat5[1,2]+conf.mat5[2,1])/(n/2)
val.set.err5
lambdamin <- cv.glmnet(xtrain,ytrain, alpha = 1, nfold = n)$lambda.min
lasso <- glmnet(xtrain, ytrain, alpha = 1, lambda = lambdamin)
lassopred <- predict(lasso, xtest)
conf.mat5 <- table(test$dir, lassopred)
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
accuracy5
val.set.err5 <- (conf.mat5[1,2]+conf.mat5[2,1])/(n/2)
val.set.err5
summary(lasso)
# R CODE MASTER THESIS:
# Libraries
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(lubridate)
library(RCurl)
library(dplyr)
library(tm)
library(stopwords)
library(quanteda)
library(boot)
library(e1071)
library(ROCR)
library(caret)
setwd("~/GitHub/thesis")
rm(list = ls())
load("df.Rdata")
# Stopwords
# Stopwords do not have capital letters or punctuation - remove
corpus =
df$text %>%
tolower(.) %>%
gsub("[[:punct:]]","",.)
# Change the articles to a corpus format
corpus =
corpus(corpus)
# Tokenize and remove stopwords
stopw = stopwords::stopwords(language = "no")
toks = corpus %>%
tokens() %>%
tokens_remove(stopw)
load("LMNorsk.RData")
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select("x" = translatedContent, y)
# SENTIMENT SCORE
# It is important that the sentiment dictionary and stopwords dictionary do not
# overlap, that would result in an unreliable sentiment score.
inner_join(data.frame(x = stopw),LM.norsk,by="x")
# Create actual sentiment score (sum of +1 and -1 values of positive/negative words
# divided by the total number of words)
score = vector()
for(t in 1:length(toks)){
score = append(score,
sum(filter(LM.norsk, x %in% toks[[t]])$y) / length(toks[[t]]))
}
# Test
sum(filter(LM.norsk, x %in% toks[[1]])$y) / length(toks[[1]]) == score[1]
sum(filter(LM.norsk, x %in% toks[[3184]])$y) / length(toks[[3184]]) == score[3184]
# Insert into df
df$sentiment = score
df <- df[!df$dir=="no change",]
# change y value to class factor
df$dir <- as.factor(df$dir)
set.seed(123)
n = nrow(df)
n.train = floor(0.8*n)
n.test = n.train+1
train = df[1:n.train,]
test = df[n.test:n,]
# with full data
logreg1 <- glm(dir~sentiment, data = df, family = binomial())
summary(logreg1)
logpred1 <- predict(logreg1, type = "response")
conf.mat1 <- table(df$dir, logpred1 > 0.5)
conf.mat1
accuracy1 <- sum(diag(conf.mat1))/sum(conf.mat1)
accuracy1
val.set.err1 <- (conf.mat1[1,2]+conf.mat1[2,1])/(n/2)
val.set.err1
# with train data
logreg2 <- glm(dir~sentiment, data = train, family = binomial())
summary(logreg2)
logpred2 <- predict(logreg2, test, type = "response")
conf.mat2 <- table(test$dir, logpred2 > 0.5)
conf.mat2
accuracy2 <- sum(diag(conf.mat2))/sum(conf.mat2)
accuracy2
val.set.err2 <- (conf.mat2[1,2]+conf.mat2[2,1])/(n/2)
val.set.err2
# k-fold cross-validation
all.cv = rep(NA, 10)
for (i in 1:10) {
logfit = glm(dir~sentiment, data=df, family = binomial())
all.cv[i] = cv.glm(df, logfit, K=10)$delta[2]
}
plot(1:10, all.cv, lwd=2, type="l", xlab="df", ylab="CV error")
# ROC
rocpred <- prediction(logpred2, test$dir)
rocperf <- performance(rocpred, "tpr", "fpr")
plot(rocperf)
# SVM classification:
tunesvm <- tune(svm, dir~sentiment, data = train, kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100, 1000)))
summary(tunesvm)
bestsvm <- tunesvm$best.model
svmpred <- predict(bestsvm, test)
conf.mat3 <- table(test$dir, svmpred)
conf.mat3
accuracy3 <- sum(diag(conf.mat3))/sum(conf.mat3)
set.seed(123)
n = nrow(df)
n.train = floor(0.8*n)
n.test = n.train+1
train = df[1:n.train,]
test = df[n.test:n,]
# with full data
logreg1 <- glm(dir~sentiment, data = df, family = binomial())
summary(logreg1)
logpred1 <- predict(logreg1, type = "response")
conf.mat1 <- table(df$dir, logpred1 > 0.5)
conf.mat1
accuracy1 <- sum(diag(conf.mat1))/sum(conf.mat1)
accuracy1
val.set.err1 <- (conf.mat1[1,2]+conf.mat1[2,1])/(n/2)
val.set.err1
# with train data
logreg2 <- glm(dir~sentiment, data = train, family = binomial())
summary(logreg2)
logpred2 <- predict(logreg2, test, type = "response")
conf.mat2 <- table(test$dir, logpred2 > 0.5)
conf.mat2
accuracy2 <- sum(diag(conf.mat2))/sum(conf.mat2)
accuracy2
val.set.err2 <- (conf.mat2[1,2]+conf.mat2[2,1])/(n/2)
val.set.err2
# k-fold cross-validation
all.cv = rep(NA, 10)
for (i in 1:10) {
logfit = glm(dir~sentiment, data=df, family = binomial())
all.cv[i] = cv.glm(df, logfit, K=10)$delta[2]
}
plot(1:10, all.cv, lwd=2, type="l", xlab="df", ylab="CV error")
# ROC
rocpred <- prediction(logpred2, test$dir)
library(ROCR)
install.packages("ROCR")
# ROC
rocpred <- prediction(logpred2, test$dir)
library(ROCR)
# ROC
rocpred <- prediction(logpred2, test$dir)
rocperf <- performance(rocpred, "tpr", "fpr")
plot(rocperf)
# SVM classification:
tunesvm <- tune(svm, dir~sentiment, data = train, kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100, 1000)))
summary(tunesvm)
bestsvm <- tunesvm$best.model
svmpred <- predict(bestsvm, test)
conf.mat3 <- table(test$dir, svmpred)
conf.mat3
accuracy3 <- sum(diag(conf.mat3))/sum(conf.mat3)
accuracy3
val.set.err3 <- (conf.mat3[1,2]+conf.mat3[2,1])/(n/2)
val.set.err3
# Linear regression:
lmreg <- lm(av.price~sentiment, data = train)
summary(lmreg)
predlm <- predict(lmreg, test)
conf.mat4 <- table(test$av.price, predlm)
conf.mat4
accuracy4 <- sum(diag(conf.mat4))/sum(conf.mat4)
accuracy4
val.set.err4 <- (conf.mat4[1,2]+conf.mat4[2,1])/(n/2)
val.set.err4
# SVM regression:
svmreg <- svm(av.price~sentiment, data = train)
summary(svmreg)
predsvmreg <- predict(svmreg, test)
conf.mat5 <- table(test$av.price, predsvmreg)
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
conf.mat5
accuracy5 <- sum(diag(conf.mat5))/sum(conf.mat5)
accuracy5
val.set.err5 <- (conf.mat5[1,2]+conf.mat5[2,1])/(n/2)
val.set.err5
library(MASS)
# Linear discriminant analysis
lda.fit = lda(dir~sentiment , data = train)
lda.fit
plot(lda.fit)
View(Smarket)
library(ISLR)
install.packages("ISLR")
library(ISLR)
summary(Smarket)
Smarket.2005
# Predict
lda.pred = predict (lda.fit, test)
names(lda.pred)
#
lda.class <- lda.pred$class
# Confusion matrix
lda.class = lda.pred$class
table(lda.class, test$dir)
# Accuracy
mean(lda.class == train$dir)
conf.mat10 = table(test$dir, lda.class)
accuracy10 = sum(diag(conf.mat10))/sum(conf.mat10)
accuracy10
mean(lda.class == train$dir)
conf.mat10 = table(test$dir, lda.class)
# Accuracy?
accuracy10 = sum(diag(conf.mat10))/sum(conf.mat10)
accuracy10
# Val set error
val.set.err10 <- (conf.mat10[1,2]+conf.mat10[2,1])/(n/2)
val.set.err10
# Quadratic linear discriminant analysis (QLDA)
qda.fit = qda(dir~sentiment, data = train)
qda.fit
# Plot
plot(qda.fit)
# Predict
qda.class = predict(qda.fit, test)$class
# Confusion matrix
conf.mat11 = table(test$dir, qlda.class)
# Predict
qda.class = predict(qda.fit, test)$class
# Confusion matrix
conf.mat11 = table(test$dir, qlda.class)
# Predict
qlda.class = predict(qda.fit, test)$class
# Quadratic discriminant analysis (QDA)
qda.fit = qda(dir~sentiment, data = train)
qda.fit
# Predict
qda.class = predict(qda.fit, test)$class
# Confusion matrix
conf.mat11 = table(test$dir, qda.class)
# Accuracy
mean(qda.class == test$dir)
accuracy11 = sum(diag(conf.mat11))/sum(conf.mat11)
mean(qda.class == test$dir)
accuracy11
mean(lda.class == test$dir)
accuracy10
# Val set error
val.set.err11 <- (conf.mat11[1,2]+conf.mat11[2,1])/(n/2)
# Overview of results from all methods:
method = c("Logistic","SVM", "GBM","KNN", "Naive bayes", "GAM", "Tree",
"RandomForest", "LDA", "QDA")
acc.all = c(accuracy2, accuracy3, accuracy4, accuracy5, accuracy6,
accuracy7, accuracy8, accuracy9, accuracy10, accuracy11)
# Libraries
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(lubridate)
library(RCurl)
library(dplyr)
library(tm)
library(stopwords)
library(quanteda)
library(boot)
library(e1071)
library(ROCR)
library(caret)
library(class)
library(gam)
library(tree)
library(randomForest)
library(MASS)
rm(list = ls())
load("df.Rdata")
# Change the articles to a corpus format
corpus =
corpus(corpus)
# Tokenize and remove stopwords
stopw = stopwords::stopwords(language = "no")
toks = corpus %>%
tokens() %>%
tokens_remove(stopw)
rm(list = ls())
load("df.Rdata")
# Stopwords
# Stopwords do not have capital letters or punctuation - remove
corpus =
df$text %>%
tolower(.) %>%
gsub("[[:punct:]]","",.)
# Change the articles to a corpus format
corpus =
corpus(corpus)
# Tokenize and remove stopwords
stopw = stopwords::stopwords(language = "no")
toks = corpus %>%
tokens() %>%
tokens_remove(stopw)
load("LMNorsk.RData")
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select("x" = translatedContent, y)
# SENTIMENT SCORE
# It is important that the sentiment dictionary and stopwords dictionary do not
# overlap, that would result in an unreliable sentiment score.
inner_join(data.frame(x = stopw),LM.norsk,by="x")
View(LM.norsk)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select("x" = translatedContent, y)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select("x" = translatedContent, y)
LM.norsk =
LM.norsk %>%
select(translatedContent, y) %>%
select("x" = translatedContent, y)
names(LM.norsk)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select(translatedContent, y)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select(x = translatedContent, y)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk %>%
select(x = translatedContent, y)
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk[2:3,]
load("LMNorsk.RData")
# There is a Norwegian alternative of a sentiment dictionary from UiO
# which is an alternative if we need it
# Sum negative/positive words
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk[,2:3]
load("LMNorsk.RData")
# There is a Norwegian alternative of a sentiment dictionary from UiO
# which is an alternative if we need it
# Sum negative/positive words
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk[,2:3] %>%
select("x" = translatedContent, y)
# Libraries
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(lubridate)
library(RCurl)
library(dplyr)
library(tm)
library(stopwords)
library(quanteda)
library(boot)
library(e1071)
library(ROCR)
library(caret)
library(class)
library(gam)
library(tree)
library(randomForest)
library(MASS)
load("LMNorsk.RData")
sum(LM.norsk$y == 1)  # Number of positive words
sum(LM.norsk$y == -1) # Number of negative words
# Remove duplicates and more than one word translations
nrow((distinct(as.data.frame(LM.norsk$translatedContent))))
which(duplicated(LM.norsk$translatedContent))
LM.norsk <- LM.norsk[!duplicated(LM.norsk$translatedContent), ]
which(sapply(strsplit(LM.norsk$translatedContent, " "), length)>1)
LM.norsk <- LM.norsk[!sapply(strsplit(LM.norsk$translatedContent, " "), length)>1, ]
# Change format of columns so LM.norsk looks exactly like the untranslated dictionary
LM.norsk =
LM.norsk[,2:3] %>%
select("x" = translatedContent, y)
# SENTIMENT SCORE
# It is important that the sentiment dictionary and stopwords dictionary do not
# overlap, that would result in an unreliable sentiment score.
inner_join(data.frame(x = stopw),LM.norsk,by="x")
?select
# Linear discriminant analysis (LDA)
lda.fit = MASS::lda(dir~sentiment , data = train)
# Linear discriminant analysis (LDA)
lda.fit = MASS::lda(dir~sentiment , data = train)
# Linear discriminant analysis (LDA)
lda.fit = MASS::lda(dir~sentiment, data = train)
?predict
