load("C:/Users/Herdis/Desktop/Master/data_for_lecture_12_2021.Rdata")
rm(list = ls())
load("df.Rdata")
setwd("~/GitHub/thesis")
# Libraries
library(readxl)
library(rvest)
library(RSelenium)
library(httr)
library(stringr)
library(BatchGetSymbols)
library(lexicon)
library(translateR)
library(lubridate)
library(RCurl)
library(dplyr)
library(tm)
library(stopwords)
library(quanteda)
library(boot)
library(e1071)
library(ROCR)
library(caret)
library(class)
library(gam)
library(tree)
library(randomForest)
library(kernlab)
rm(list = ls())
load("df.RData")
# CLASSIFICATION:
# Remove days with no change (better accuracy)
df <- df[!df$dir=="no change",]
# This creates a NA row - remove
df = na.omit(df)
# change y value to class factor
df$dir <- as.factor(df$dir)
# Split data:
set.seed(1)
n = nrow(df)
n.train = floor(0.9*n)
n.test = n.train+1
train = df[1:n.train,]
test = df[n.test:n,]
# Cross validation method: 10-fold cross validation
ctrl <- trainControl(method = "cv", number = 10)
# Logistic regression:
set.seed(1)
logreg <- train(dir~sentiment, data = train, method = "glm", family = binomial,
trControl = ctrl)
logpred <- predict(logreg, test)
confusionMatrix(logpred, test$dir)
conf.mat <- confusionMatrix(logpred, test$dir)[[2]]
accuracy <- sum(diag(conf.mat))/sum(conf.mat)
accuracy
val.set.err <- (conf.mat[1,2]+conf.mat[2,1])/(n/2)
val.set.err
rocpred1 <- prediction(as.numeric(logpred), test$dir)
rocperf1 <- performance(rocpred1, "tpr", "fpr")
plot(rocperf1, main = "ROC curve", col = "red")
AUC1 <- confusionMatrix(logpred, test$dir)[[4]][11]
text(0.4, 0.67, "AUC =")
text(0.4, 0.6, format(round(AUC1, 4)))
lines(x = c(0,1), y = c(0,1), type = "l", lty = 2)
legend(0, 1, legend=c("ROC curve", "Random"),
col=c("red", "black"), lty=1:2, cex=0.8)
graphics.off()
# SVM classification:
set.seed(1)
svmreg <- train(dir~sentiment, data = train, method = "svmLinear",
trControl = ctrl)
svmpred <- predict(svmreg, test)
confusionMatrix(svmpred, test$dir)[[4]][1]
conf.mat2 <- confusionMatrix(svmpred, test$dir)[[2]]
accuracy2 <- sum(diag(conf.mat2))/sum(conf.mat2)
accuracy2
val.set.err2 <- (conf.mat2[1,2]+conf.mat2[2,1])/(n/2)
val.set.err2
rocpred2 <- prediction(as.numeric(svmpred), test$dir)
rocperf2 <- performance(rocpred2, "tpr", "fpr")
plot(rocperf2, main = "ROC curve", col = "green")
AUC2 <- confusionMatrix(svmpred, test$dir)[[4]][11]
text(0.4, 0.67, "AUC =")
text(0.4, 0.6, format(round(AUC2, 4)))
lines(x = c(0,1), y = c(0,1), type = "l", lty = 2)
legend(0, 1, legend=c("ROC curve", "Random"),
col=c("green", "black"), lty=1:2, cex=0.8)
graphics.off()
# GBM classification:
set.seed(1)
xtrain = train[,11:12]
ytrain = train$dir
xtest = test[,11:12]
ytest = test$dir
x = cbind(xtrain, ytrain)
set.seed(1)
gbmfit = train(dir~sentiment, data=xtrain, method="gbm",
distribution = "bernoulli", trControl=ctrl)
gbmpred = predict(gbmfit, xtest)
confusionMatrix(gbmpred, ytest)
conf.mat3 <- confusionMatrix(gbmpred, ytest)[[2]]
accuracy3 <- sum(diag(conf.mat3))/sum(conf.mat3)
accuracy3
val.set.err3 <- (conf.mat3[1,2]+conf.mat3[2,1])/(n/2)
val.set.err3
rocpred3 <- prediction(as.numeric(gbmpred), test$dir)
rocperf3 <- performance(rocpred3, "tpr", "fpr")
plot(rocperf3, main = "ROC curve", col = "blue")
AUC3 <- confusionMatrix(gbmpred, test$dir)[[4]][11]
text(0.4, 0.67, "AUC =")
text(0.4, 0.6, format(round(AUC3, 4)))
lines(x = c(0,1), y = c(0,1), type = "l", lty = 2)
legend(0, 1, legend=c("ROC curve", "Random"),
col=c("blue", "black"), lty=1:2, cex=0.8)
graphics.off()
# K-Nearest Neighbors:
set.seed(1)
knn <- train(dir~sentiment, data = train, method = "knn", trControl = ctrl)
knnpred <- predict(knn, test)
confusionMatrix(knnpred, test$dir)
conf.mat4 <- confusionMatrix(knnpred, test$dir)[[2]]
accuracy4 <- sum(diag(conf.mat4))/sum(conf.mat4)
accuracy4
val.set.err4 <- (conf.mat4[1,2]+conf.mat4[2,1])/(n/2)
val.set.err4
rocpred4 <- prediction(as.numeric(knnpred), test$dir)
rocperf4 <- performance(rocpred4, "tpr", "fpr")
plot(rocperf4, main = "ROC curve", col = "orange")
AUC4 <- confusionMatrix(knnpred, test$dir)[[4]][11]
text(0.4, 0.67, "AUC =")
text(0.4, 0.6, format(round(AUC4, 4)))
lines(x = c(0,1), y = c(0,1), type = "l", lty = 2)
legend(0, 1, legend=c("ROC curve", "Random"),
col=c("orange", "black"), lty=1:2, cex=0.8)
graphics.off()
# Overview of results from logistic, SVM, GBM and KNN:
method = c("Logistic","SVM", "GBM","KNN")
acc.all = c(accuracy, accuracy2, accuracy3, accuracy4)
vse.all = c(val.set.err, val.set.err2, val.set.err3, val.set.err4)
final.table = data.frame(method,
"Accuracy" = acc.all,
"Validation set error" = vse.all)
View(final.table)
confusionMatrix(logpred, test$dir)
confusionMatrix(knnpred, test$dir)
n.train = floor(0.9*n)
n.train
n.test
nrow(train)
nrow(test)
confusionMatrix(gbmpred, ytest)
confusionMatrix(svmpred, test$dir)[[4]][1]
conf.mat2
confusionMatrix(svmpred, test$dir)[[4]][1]
conf.mat2 <- confusionMatrix(svmpred, test$dir)[[2]]
conf.mat2
3141+349
3141/3490
